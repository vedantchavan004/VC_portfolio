<!DOCTYPE html>
<html data-theme="light" lang="en">

<head>
  <meta charset="utf-8" />
  <meta content="IE=edge" http-equiv="X-UA-Compatible" />
  <meta content="width=device-width, initial-scale=1.0" name="viewport" />
  <title>Vedant Chavan</title>
  <link href="style.css" rel="stylesheet" />
  <link href="./assets/logo.png" rel="icon" type="image/png" />

  <style>
    /* Experience summary caret rotation */
    .exp-summary .exp-caret { transition: transform .3s ease; }
    details[open] .exp-summary .exp-caret { transform: rotate(180deg); }

    /* Skills accordion fallback */
    #skills .skill-card .card-content{max-height:0;overflow:hidden;transition:max-height .4s ease,padding .3s ease;}
    #skills .skill-card.expanded .card-content{padding-top:.90rem}
    #skills .skill-card .toggle-icon{transition:transform .3s ease;display:inline-block}
    #skills .skill-card.expanded .toggle-icon{transform:rotate(180deg)}
  </style>

</head>

<body>
  <nav id="desktop-nav">
    <div class="logo">Vedant Chavan</div>
    <ul class="nav-links">
      <li><a data-i18n="nav.about" href="#about">About</a></li>
      <li><a data-i18n="nav.skills" href="#skills">Skills</a></li>
      <li><a data-i18n="nav.experience" href="#experience">Experience</a></li>
      <li><a data-i18n="nav.projects" href="#projects">Projects</a></li>
      <li><a data-i18n="nav.contact" href="#contact">Contact</a></li>

      <li class="theme-switch-container">
        <div class="theme-switch-wrapper">
          <span aria-hidden="true" class="theme-icon-container" id="theme-icon-desktop">
          </span>
          <label aria-label="Toggle theme" class="theme-switch" for="theme-toggle-desktop">
            <input id="theme-toggle-desktop" title="Toggle theme" type="checkbox" />
            <span class="slider round"></span>
          </label>
        </div>
      </li>
    </ul>
  </nav>
  <nav id="hamburger-nav">
    <div class="logo">Vedant Chavan</div>
    <div class="hamburger-menu">
      <div class="hamburger-icon">
        <span></span>
        <span></span>
        <span></span>
      </div>
      <div class="menu-links">
        <li><a href="#about">About</a></li>
        <li><a href="#skills">Skills</a></li>
        <li><a href="#experience">Experience</a></li>
        <li><a href="#projects">Projects</a></li>
        <li><a href="#contact">Contact</a></li>
        <li>
          <div class="theme-switch-wrapper-mobile">
            <div id="theme-icon-mobile" class="theme-icon-container">
              <!-- Icon will be injected by JS -->
            </div>
            <label class="theme-switch" for="theme-toggle-mobile">
              <span class="sr-only">Toggle theme</span>
              <input type="checkbox" id="theme-toggle-mobile" />
              <div class="slider round"></div>
            </label>
          </div>
        </li>
      </div>
    </div>
  </nav>
  <div id="menu-overlay" onclick="toggleMenu()"></div>
  <section id="profile">
    <div class="section__pic-container">
      <img alt="Vedant Chavan" src="./assets/Picture1.png" />
    </div>
    <div class="section__text">
      <p class="section__text__p1" data-i18n="profile.hello">Hello, I'm</p>
      <h1 class="title">Vedant Chavan</h1>
      <span class="section__text__p2" id="typing-animation"></span>
      <br />
      <br />
      <div class="btn-container">
        <div class="cv-dropdown-container">
          <button class="btn btn-color-2" id="download-cv-btn" aria-haspopup="true" aria-expanded="false">
            <span data-i18n="buttons.download_cv">Download CV</span> ▾
          </button>
          <div class="cv-dropdown" id="cv-dropdown" role="menu" aria-labelledby="download-cv-btn">
            <a role="menuitem" class="cv-item" href="./assets/Vedant_Chavan_CV.pdf" download data-i18n="buttons.download_cv_en">CV (EN)</a>
            <a role="menuitem" class="cv-item" href="./assets/Vedant_Chavan_Lebenslauf.pdf" download data-i18n="buttons.download_cv_de">Lebenslauf (DE)</a>
          </div>
        </div>
        <button class="btn btn-color-1" data-i18n="buttons.contact_info" onclick="location.href='#contact'">
          Contact Info
        </button>
      </div>
      <br />
      <div id="socials-container">
        <a aria-label="LinkedIn Profile" href="https://www.linkedin.com/in/vedant-chavan-97ml/" rel="noopener noreferrer" target="_blank">
          <svg class="icon icon-linkedin" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
            <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z" fill="currentColor"></path>
          </svg>
        </a>
        <a aria-label="GitHub Profile" href="https://github.com/vedantchavan004/" rel="noopener noreferrer" target="_blank">
          <svg class="icon icon-github" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
            <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z" fill="currentColor"></path>
          </svg>
        </a>
      </div>
    </div>
    <br />
    <br />
    <br />
  </section>
  <!-- About Section (Improved) -->
  <section id="about">
    <div class="about-header">
      <p class="section__text__p1" data-i18n="about.subtitle">Get To Know More</p>
      <h1 class="title" data-i18n="about.title">About Me</h1>
    </div>
    <div class="about-content">
      <!-- <div class="about-image">
                <img src="./assets/about1.jpg" alt="About me" />
            </div> -->
      <div class="about-info">
        <p data-i18n="about.blurb">
          I'm Vedant Sanjay Chavan, an AI & Computer Vision Engineer specializing in 3D perception, deep learning, and real-time vision systems.
I’ve worked on stereo vision and adaptive perception algorithms at FORVIA HELLA, developing lightweight CNNs and synthetic datasets for automotive AI.
With an M.Eng. in Mechatronics and experience across machine learning, geometry, and generative AI, I focus on building intelligent systems that bridge the physical and digital worlds — from autonomous perception to industrial inspection.
        </p>
        <div class="about-stats">
          <!-- <div class="stat">
<svg aria-label="Experience Icon" class="stat-icon icon-experience" fill="currentColor" height="24" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M20 6h-4V4c0-1.11-.89-2-2-2h-4c-1.11 0-2 .89-2 2v2H4c-1.11 0-2 .89-2 2v11c0 1.11.89 2 2 2h16c1.11 0 2-.89 2-2V8c0-1.11-.89-2-2-2zM10 4h4v2h-4V4zm10 15H4V8h16v11z"></path>
</svg>
<h3><span data-i18n="about.stat.years">2+ Years</span></h3>
<p><span data-i18n="about.stat.years_desc">Experience in developing AI solutions</span></p>
</div> -->
          <div class="stat">
            <a href="./assets/MEng.pdf" rel="noopener noreferrer" style="text-decoration: none; color: inherit;" target="_blank">
              <svg aria-label="Degree Icon" class="stat-icon icon-degree" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M5,13.18V17.17L12,21L19,17.17V13.18L12,17L5,13.18M12,3L1,9L12,15L23,9L12,3Z" fill="currentColor"></path>
              </svg>
              <h3>M.Eng. in Mechatronics</h3>
              <p><span data-i18n="about.stat.meng_field">Technischen Hochschule Rosenheim, Germany</span></p>
            </a>
          </div>

          <div class="stat">
            <a href="./assets/BTech.pdf" rel="noopener noreferrer" style="text-decoration: none; color: inherit;" target="_blank">
              <svg aria-label="Degree Icon" class="stat-icon icon-degree" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M5,13.18V17.17L12,21L19,17.17V13.18L12,17L5,13.18M12,3L1,9L12,15L23,9L12,3Z" fill="currentColor"></path>
              </svg>
              <h3>B.Tech. in Mechanical Engineering</h3>
              <p><span data-i18n="about.stat.btech_field">Vellore Institute of Technology, India</span></p>
            </a>
          </div>

        </div>
      </div>
    </div>
  </section>
  <!-- Skills Section with Accordion Cards -->
  <!-- ===== SKILLS (working dropdowns) ===== -->
  <section id="skills" aria-labelledby="skills-title">
    <div class="skills-header">
      <p class="section__text__p1">Core Expertise</p>
      <h1 id="skills-title" class="title">Main Skills</h1>
    </div>
    <div class="skills-grid">
      <!-- Category: 3D Perception -->
      <div class="skill-category-card">
        <h3>3D Perception</h3>
        <div class="skill-items">
          <span>Stereo Vision</span>
          <span>Multi‑Sensor Fusion</span>
          <span>Triangulation</span>
          <span>Calibration</span>
          <span>3D Reconstruction</span>
          <span>Point Cloud Processing</span>
          <span>SLAM</span>
        </div>
      </div>
      <!-- Category: Deep Learning -->
      <div class="skill-category-card">
        <h3>Deep Learning</h3>
        <div class="skill-items">
          <span>2D/3D Detection &amp; Tracking</span>
          <span>Segmentation</span>
          <span>Anomaly Detection</span>
        </div>
      </div>
      <!-- Category: Frameworks & Tools -->
      <div class="skill-category-card">
        <h3>Frameworks &amp; Tools</h3>
        <div class="skill-items">
          <span>PyTorch</span>
          <span>TensorFlow</span>
          <span>OpenCV</span>
          <span>ONNX Runtime</span>
          <span>CUDA</span>
          <span>Unreal Engine 5</span>
          <span>COLMAP</span>
          <span>Open3D</span>
          <span>Docker</span>
        </div>
      </div>
      <!-- Category: Programming -->
      <div class="skill-category-card">
        <h3>Programming</h3>
        <div class="skill-items">
          <span>Python (advanced)</span>
          <span>C++ (intermediate)</span>
          <span>Bash</span>
        </div>
      </div>
      <!-- Category: Optimization & Deployment -->
      <div class="skill-category-card">
        <h3>Optimization &amp; Deployment</h3>
        <div class="skill-items">
          <span>TensorRT</span>
          <span>Quantization</span>
          <span>AWS</span>
          <span>CI/CD (GitHub Actions)</span>
        </div>
      </div>
      <!-- Category: Generative AI / LLMs -->
      <div class="skill-category-card">
        <h3>Generative AI / LLMs</h3>
        <div class="skill-items">
          <span>LangChain</span>
          <span>FAISS</span>
          <span>Streamlit</span>
          <span>Hugging Face</span>
          <span>Prompt Engineering</span>
        </div>
      </div>
    </div>
  </section>

  <!-- Experience Section -->
  <!-- ===== EXPERIENCE (NEW TIMELINE) ===== -->
<section id="experience" aria-labelledby="exp-title">
  <div class="experience-header">
    <p class="section__text__p1">Browse My Recent</p>
    <h1 class="title" id="exp-title">Experience</h1>
  </div>

  <ol class="exp-timeline">
    <!-- HELLA — AI Research Intern -->
    <li class="exp-timeline-item">
      <details class="exp-item" aria-labelledby="exp-hella-intern">
        <summary class="exp-summary" id="exp-hella-intern">
          <span class="exp-dot" aria-hidden="true"></span>
          <div class="exp-summary-main">
            <div class="exp-company-role">
              <h3 class="exp-company">AI Research Intern — FORVIA HELLA (AHEAD Project)</h3>
            </div>
            <div class="exp-meta">
              <span class="exp-location">Lippstadt, Germany</span>
              <span class="exp-date">Aug 2023 – Feb 2024</span>
            </div>
            <p class="exp-summary-short">
              Developed perception models for adaptive headlights using stereo vision and deep learning. Improved night-time detection accuracy by 30% and achieved real-time 3D localization with embedded GPUs.
            </p>
            <span class="exp-caret" aria-hidden="true">▼</span>
          </div>
        </summary>
        <div class="exp-content">
          <div class="slideshow-container" data-slideshow-id="internship">
            <div class="slideshow-inner">
              <div class="slide active"><img src="./assets/internship/object dtection with yolo.jpg" alt="Object Detection with YOLO"></div>
              <div class="slide"><img src="./assets/internship/feature matching.png" alt="Feature Matching"></div>
              <div class="slide"><img src="./assets/internship/lane segmentation.jpg" alt="Lane Segmentation"></div>
              <div class="slide"><img src="./assets/internship/object matching and tracking.png" alt="Object Matching and Tracking"></div>
              <div class="slide"><img src="./assets/internship/road trajectory.png" alt="Road Trajectory"></div>
            </div>
            <button class="prev" aria-label="Previous image">❮</button>
            <button class="next" aria-label="Next image">❯</button>
          </div>
          <div class="exp-detail-block">
            <h4>Goal</h4>
            <p>Improve night-time perception for adaptive headlights by enabling reliable object detection and lane understanding under glare, rain, and low-illumination conditions.</p>
          </div>
          <div class="exp-detail-block">
            <h4>Approach</h4>
            <ul class="experience-details">
              <li>Adapted and fine-tuned YOLOv8 for glare-robust detection using extensive augmentation and hyper-parameter tuning.</li>
              <li>Designed a modular perception pipeline combining detection, segmentation, and multi-object tracking (DeepSORT + OpenCV).</li>
              <li>Implemented stereo triangulation and calibration to obtain real-world 3D localization and lane geometry.</li>
              <li>Performed robustness and uncertainty analyses for varying lighting, motion blur, and sensor noise.</li>
              <li>Collaborated with optics and embedded teams to validate models in prototype headlight systems.</li>
            </ul>
          </div>
          <div class="exp-detail-block">
            <h4>Results</h4>
            <ul class="experience-details">
              <li>Improved low-light detection mAP by ≈ 30% compared to baseline.</li>
              <li>Achieved highly stable 3D localization validated against laser ground truth.</li>
              <li>Enabled real-time inference through Dockerized GPU pipelines for reproducible testing.</li>
            </ul>
          </div>
          <p class="exp-impact">This work was presented to the R&D and perception teams at HELLA and influenced ongoing ADAS prototype development.</p>
          <p class="tech-stack"><strong>Tech Stack:</strong> Python · PyTorch · OpenCV · YOLOv8 · DeepSORT · ONNX Runtime · Docker · Stereo Calibration · Triangulation</p>
        </div>
      </details>
    </li>

    <!-- HELLA — Master’s Thesis Researcher -->
    <li class="exp-timeline-item">
      <details class="exp-item" aria-labelledby="exp-hella-thesis">
        <summary class="exp-summary" id="exp-hella-thesis">
          <span class="exp-dot" aria-hidden="true"></span>
          <div class="exp-summary-main">
            <div class="exp-company-role">
              <h3 class="exp-company">Master’s Thesis — Stereo Vision for Adaptive Headlight Systems</h3>
            </div>
            <div class="exp-meta">
              <span class="exp-location">Lippstadt, Germany</span>
              <span class="exp-date">Mar 2024 – Nov 2024</span>
            </div>
             <p class="exp-summary-short">
              Built a lightweight stereo CNN for long-range depth estimation and 3D object localization. Generated 9,000+ synthetic pairs in Unreal Engine 5 and optimized inference latency to 70 ms.
            </p>
            <span class="exp-caret" aria-hidden="true">▼</span>
          </div>
        </summary>
        <div class="exp-content">
          <div class="slideshow-container" data-slideshow-id="thesis">
            <div class="slideshow-inner">
                <div class="slide active"><img src="./assets/thesis/model architecture.png" alt="Model Architecture"></div>
                <div class="slide"><img src="./assets/thesis/Ego vehicle.jpg" alt="Ego Vehicle"></div>
                <div class="slide"><img src="./assets/thesis/kitti disparity prediction.png" alt="KITTI Disparity Prediction"></div>
                <div class="slide"><img src="./assets/thesis/predicted depth map.jpg" alt="Predicted Depth Map"></div>
                <div class="slide"><img src="./assets/thesis/predicted depth of objects.jpg" alt="Predicted Depth of Objects"></div>
            </div>
            <button class="prev" aria-label="Previous image">❮</button>
            <button class="next" aria-label="Next image">❯</button>
          </div>
          <div class="exp-detail-block">
            <h4>Goal</h4>
            <p>Develop a lightweight deep-learning model for dense depth estimation and 3D object localization in adaptive headlight control.</p>
          </div>
          <div class="exp-detail-block">
            <h4>Approach</h4>
            <ul class="experience-details">
              <li>Designed a stereo CNN (autoencoder + cost-volume fusion) for real-time depth perception.</li>
              <li>Generated ≈ 9,000 synthetic stereo pairs in Unreal Engine 5 with calibrated intrinsics to simulate weather, glare, and reflections.</li>
              <li>Applied domain randomization and fine-tuned on real test data to minimize the sim-to-real gap.</li>
              <li>Combined depth maps with YOLO detections for object localization and trajectory estimation.</li>
              <li>Exported optimized ONNX models to embedded GPUs and validated inference performance jointly with hardware and optics teams.</li>
            </ul>
          </div>
          <div class="exp-detail-block">
            <h4>Results</h4>
            <ul class="experience-details">
              <li>Achieved 3% D1-all error on KITTI benchmark and ≈ 95% depth accuracy at 30m on real data.</li>
              <li>Reduced inference latency from 120 → 70 ms through ONNX Runtime optimization.</li>
              <li>Delivered complete calibration, benchmarking, and uncertainty documentation adopted by HELLA’s internal R&D teams.</li>
            </ul>
          </div>
          <p class="exp-impact">This work was presented to the R&D and perception teams at HELLA and influenced ongoing ADAS prototype development.</p>
          <p class="tech-stack"><strong>Tech Stack:</strong> PyTorch · YOLOv8 · Unreal Engine 5 · OpenCV · CUDA · ONNX Runtime · Docker · Calibration QA · Synthetic Data Generation</p>
        </div>
      </details>
    </li>

    <!-- Indpro — Automation Engineer -->
    <li class="exp-timeline-item">
      <details class="exp-item" aria-labelledby="exp-indpro">
        <summary class="exp-summary" id="exp-indpro">
          <span class="exp-dot" aria-hidden="true"></span>
          <div class="exp-summary-main">
            <div class="exp-company-role">
              <h3 class="exp-company">Automation Engineer — Indpro Electronic Systems Private Limited</h3>
            </div>
            <div class="exp-meta">
              <span class="exp-location">Pune, India</span>
              <span class="exp-date">May 2019 – Mar 2020</span>
            </div>
            <span class="exp-caret" aria-hidden="true">▼</span>
          </div>
        </summary>
        <div class="exp-content">
          <ul class="experience-details">
            <li>Developed and deployed PLC control logic (ABB AC800M) for sugar-industry automation systems.</li>
            <li>Designed HMI dashboards and supported on-site commissioning and troubleshooting across multiple facilities.</li>
          </ul>
          <p class="tech-stack">Tech: ABB AC800M PLC, PLC Programming, HMI (SCADA), Industrial Automation</p>
        </div>
      </details>
    </li>
  </ol>
</section>
<!-- ===== END EXPERIENCE ===== -->
  <!-- Projects Section -->
  <section id="projects">
    <p class="section__text__p1" data-i18n="projects.subtitle">Browse My Recent</p>
    <h1 class="title" data-i18n="projects.title">Projects</h1>
    <!-- Featured Projects (Visible by default) -->
    <div class="projects-grid" id="featured-projects">
      <!-- Project 1 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 3" class="project-img" src="./assets/binpicking.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p1.title">Custom YOLO for Robotic Bin Picking</h2>
        <p class="project-info" data-i18n="projects.p1.info">Developed a custom YOLO model for detecting objects in bin picking tasks, achieving 98% precision in 6D pose estimation.</p>
        <div class="project-skills">
          <span class="skill-chip">TensorFlow</span>
          <span class="skill-chip">YOLO</span>
          <span class="skill-chip">Bin Picking</span>
          <span class="skill-chip">Blender</span>
          <span class="skill-chip">OpenCV</span>
          <span class="skill-chip">Matplotlib</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project3-details">
          <ul>
            <li>Developed a YOLO-based 6D pose estimation model in TensorFlow for precise object detection and orientation prediction in bin-picking tasks.</li>
            <li>Generated and annotated hybrid datasets using Blender (synthetic) and real camera images to improve robustness under varying lighting and occlusion.</li>
            <li>Integrated the perception system with an ABB YuMi cobot for automated pick-and-place; achieved 98% grasp success rate in real industrial tests.</li>
            <li>Optimized inference speed and detection stability for edge deployment, ensuring reliable operation in dynamic environments.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/YOLO-For-Object-Detection-and-Localization-in-Bin-Picking-Application', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project3-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div><!-- Project 2 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 2" class="project-img" src="./assets/depth.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p2.title">Deep Stereo Vision for Nighttime Driving Scenes</h2>
        <p class="project-info" data-i18n="projects.p2.info">Built a lightweight stereo CNN for adaptive headlights — achieving 95% depth accuracy at 30m and 3% D1-all on KITTI.</p>
        <div class="project-skills">
          <span class="skill-chip">PyTorch</span>
          <span class="skill-chip">Unreal Engine 5</span>
          <span class="skill-chip">MATLAB</span>
          <span class="skill-chip">OpenCV</span>
          <span class="skill-chip">Stereo Depth</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project2-details">
          <ul>
            <li>Developed a lightweight stereo CNN in PyTorch for real-time depth estimation in low-light automotive environments.</li>
            <li>Generated 9,000+ synthetic stereo pairs in Unreal Engine 5 simulating illumination, reflection, and weather variations to enhance generalization.</li>
            <li>Achieved 3% D1-all error on KITTI and 95% real-world depth accuracy at 30m; optimized inference latency from 120 → 70ms via ONNX Runtime.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/Deep-Stereo-Vision-for-nighttime-Driving-Scenes', '_blank')">Github</button>
          <button aria-controls="project2-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div><!-- Project 3.8 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Gaussian Splatting" class="project-img" src="./assets/castle.PNG" />
        </div>
        <h2 class="project-title" data-i18n="projects.p3.title">3D Reconstruction with Gaussian Splatting</h2>
        <p class="project-info" data-i18n="projects.p3.info">Converted monocular smartphone video into a dense 3D scene using COLMAP preprocessing and Gaussian Splatting rendering.</p>
        <div class="project-skills">
          <span class="skill-chip">COLMAP</span>
          <span class="skill-chip">WSL</span>
          <span class="skill-chip">Supersplat</span>
          <span class="skill-chip">Gaussian Splatting</span>
          <span class="skill-chip">Open3D</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project3.8-details">
          <ul>
            <li data-i18n="projects.p3.d1">Extracted camera poses and sparse point clouds using <strong>COLMAP</strong> from monocular input video.</li>
            <li data-i18n="projects.p3.d2">Used <strong>Gaussian Splatting</strong> to render photorealistic 3D views with transparency and shading effects.</li>
            <li data-i18n="projects.p3.d3">Visualized and explored outputs in <strong>Open3D</strong>, and investigated mesh conversion workflows.</li>
            <li data-i18n="projects.p3.d4">Handled lighting, occlusion, and splat shaders for high-fidelity rendering of complex indoor scenes.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://vedantchavan004.github.io/3D-Reconstruction-using-Gaussian-Splatting/', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project3.8-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div>
    </div>
    <!-- Additional Projects (Hidden by default) -->
    <div class="projects-grid hidden" id="additional-projects">
      <!-- Project 2.5 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 2.5" class="project-img" src="./assets/bikes.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p4.title">Object Instance segmentation with FastAPI and AWS</h2>
        <p class="project-info" data-i18n="projects.p4.info">YOLOv11 instance segmentation deployed via FastAPI, containerized with Docker on AWS EC2/ECR, and automated using GitHub Actions CI/CD.</p>
        <div class="project-skills">
          <span class="skill-chip">YOLO</span>
          <span class="skill-chip">AWS</span>
          <span class="skill-chip">Docker</span>
          <span class="skill-chip">CI/CD</span>
          <span class="skill-chip">FastAPI</span>
          <span class="skill-chip">Segmentation</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project25-details">
          <ul>
            <li data-i18n="projects.p4.d1">Real-Time Object Detection &amp; Segmentation: Uses YOLOv11 for accurate instance segmentation.</li>
            <li data-i18n="projects.p4.d2">FastAPI Backend: Serves the model predictions via REST API.</li>
            <li data-i18n="projects.p4.d3">User-Friendly Web Interface: Allows users to upload images and view detected objects.</li>
            <li data-i18n="projects.p4.d4">Dockerized &amp; Cloud-Hosted: Containerized using Docker, pushed to AWS ECR, and deployed on AWS EC2.</li>
            <li data-i18n="projects.p4.d5">Automated CI/CD Pipeline: Uses GitHub Actions for continuous deployment.</li>
            (live demo may not work because of EC2 instance being overused)
          </ul>
          <div class="btn-container">
            <button class="btn project-btn" data-i18n="buttons.live_demo" onclick="window.open('http://3.124.205.250:8000/', '_blank', 'noopener,noreferrer')">
              Live Demo
            </button>
          </div>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/Image-Segmentation-AWS-MLOps', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project25-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div>
      <!-- Project 3.5 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 3.5" class="project-img" src="./assets/result_007.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p5.title">Anomaly Detection for PCB Inspection</h2>
        <p class="project-info" data-i18n="projects.p5.info">Built a lightweight visual anomaly detection system using PaDiM and ONNX for industrial defect detection.</p>
        <div class="project-skills">
          <span class="skill-chip">ONNX Runtime</span>
          <span class="skill-chip">Anomaly Detection</span>
          <span class="skill-chip">ONNX</span>
          <span class="skill-chip">Matplotlib</span>
          <span class="skill-chip">MobileNetV3</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project35-details">
          <ul>
            <li data-i18n="projects.p5.d1">Extracted multi-level features from MobileNetV3 and computed Mahalanobis-based anomaly scores at pixel level.</li>
            <li data-i18n="projects.p5.d2">Exported the feature extractor to ONNX and performed inference using ONNX Runtime for cross-platform compatibility.</li>
            <li data-i18n="projects.p5.d3">Visualized anomalies with heatmaps and binary masks using images from the MVTec AD dataset.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/Testing-Anomaly-Detection-with-PaDiM-ONNX', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project35-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div><!-- Project 3.7 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="U-Net Segmentation" class="project-img" src="./assets/unet_result.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p6.title">U-Net for Biological Image Segmentation</h2>
        <p class="project-info" data-i18n="projects.p6.info">Trained a U-Net model on fluorescence microscopy images to segment nuclei structures with high accuracy.</p>
        <div class="project-skills">
          <span class="skill-chip">Colab</span>
          <span class="skill-chip">PyTorch</span>
          <span class="skill-chip">Segmentation</span>
          <span class="skill-chip">Matplotlib</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project3.7-details">
          <ul>
            <li data-i18n="projects.p6.d1">Parsed and preprocessed instance masks into binary labels using CLAHE and Gaussian blur.</li>
            <li data-i18n="projects.p6.d2">Built a lightweight U-Net in PyTorch; trained for 100 epochs on nuclei segmentation dataset.</li>
            <li data-i18n="projects.p6.d3">Achieved Dice score of <strong>0.89</strong> and IoU of <strong>0.82</strong> on the validation set.</li>
            <li data-i18n="projects.p6.d4">Visualized predicted masks and prepared inference-ready model using Colab.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/Biological-Image-Segmentation', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project3.7-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div><!-- Project 3.7 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 1" class="project-img" src="./assets/chat.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p7.title">Conversational AI Chatbot with RAG &amp; LLM Fine-Tuning</h2>
        <p class="project-info" data-i18n="projects.p7.info">Developed a GPT-based conversational AI assistant, integrated FAISS vector search, and deployed using Docker &amp; Hugging Face Spaces.</p>
        <div class="project-skills">
          <span class="skill-chip">Hugging Face / Transformers</span>
          <span class="skill-chip">FAISS</span>
          <span class="skill-chip">RAG</span>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://huggingface.co/spaces/vedantchavan097/AI-chatbot/tree/main', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button class="btn project-btn" data-i18n="buttons.live_demo" onclick="window.open('https://huggingface.co/spaces/vedantchavan097/AI-chatbot', '_blank', 'noopener,noreferrer')">
            Live Demo
          </button>
        </div>
      </div><!-- Project 3.6 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 0" class="project-img" src="./assets/gauge_output.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p8.title">GaugeVision</h2>
        <p class="project-info" data-i18n="projects.p8.info">The goal is to simplify gauge monitoring and tagging by using YOLOv11 pose model and QR detector.</p>
        <div class="project-skills">
          <span class="skill-chip">YOLOv11</span>
          <span class="skill-chip">OpenCV</span>
          <span class="skill-chip">RoboFlow</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project0-details">
          <ul>
            <li data-i18n="projects.p8.d1">Trained a custom YOLOv11 pose model to detect keypoints on analog pressure gauges.</li>
            <li data-i18n="projects.p8.d2">Integrated OpenCV's QR code detector to read identification tags placed on or near gauges.</li>
            <li data-i18n="projects.p8.d3">Combined both outputs visually to show needle direction and QR data in one intuitive display.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/GaugeVision', '_blank')">Github</button>
          <button aria-controls="project0-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div><!-- Project: Edge Detector GUI -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Edge Detector GUI" class="project-img" src="./assets/qt_result.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p9.title">Edge Detector GUI (Qt + OpenCV + C++)</h2>
        <p class="project-info" data-i18n="projects.p9.info">Built an interactive desktop app using Qt and OpenCV for visualizing Sobel and Canny edge detection with real-time threshold sliders.</p>
        <div class="project-skills">
          <span class="skill-chip">OpenCV</span>
          <span class="skill-chip">QT</span>
          <span class="skill-chip">C++</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project-edge-details">
          <ul>
            <li data-i18n="projects.p9.d1">Integrated OpenCV with Qt to enable real-time image processing using Sobel and Canny filters.</li>
            <li data-i18n="projects.p9.d2">Added dynamic UI with sliders and dropdowns for live threshold tuning and filter selection.</li>
            <li data-i18n="projects.p9.d3">Designed clean modular C++ logic with CMake for cross-platform build compatibility.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/QT_GUI_edge_detector', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project-edge-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div><!-- Project 4 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="BLIP-1 Optimization Demo" class="project-img" src="./assets/vqa.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p10.title">BLIP-1 Optimization for Efficient Image Captioning</h2>
        <p class="project-info" data-i18n="projects.p10.info">Optimized BLIP-1 image-captioning on CPU via dynamic quantization and pruning, achieving 1.42× speedup with no accuracy loss.</p>
        <div class="project-skills">
          <span class="skill-chip">Quantization</span>
          <span class="skill-chip"> L1 pruning</span>
        </div>
        <div class="project-details hidden" id="project4-details">
          <ul>
            <li data-i18n="projects.p10.d1">Baseline BLIP-1 CPU inference in 0.69 s for correct captions.</li>
            <li data-i18n="projects.p10.d2">Applied dynamic quantization to all Linear layers, reducing latency to 0.48 s.</li>
            <li data-i18n="projects.p10.d3">Combined 30% L1 pruning + quantization for a 1.40× speedup.</li>
            <li data-i18n="projects.p10.d4">Preserved caption quality (“a man and his dog”) across all variants.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" onclick="window.open('https://github.com/vedantchavan004/Multimodal-VQA', '_blank', 'noopener,noreferrer')">
            GitHub
          </button>
          <button aria-controls="project4-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">
            More Details
          </button>
        </div>
      </div><!-- Project 5 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 5" class="project-img" src="./assets/project_3.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p11.title">Stereo Point Cloud Reconstruction</h2>
        <p class="project-info" data-i18n="projects.p11.info">Built a stereo vision pipeline for 3D point cloud reconstruction, achieving dense 3D models using SGBM and filtering.</p>
        <div class="project-skills">
          <span class="skill-chip">OpenCV</span>
          <span class="skill-chip">3D Vision</span>
          <span class="skill-chip">Stereo Matching</span>
          <span class="skill-chip">Calibration</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project5-details">
          <ul>
            <li data-i18n="projects.p11.d1">Developed a robust stereo vision pipeline using OpenCV to compute disparity maps and reconstruct 3D point clouds from stereo images, improving depth estimation accuracy.</li>
            <li data-i18n="projects.p11.d2">Optimized disparity computation by fine-tuning SGBM parameters and applying filtering techniques, reducing noise and enhancing 3D reconstruction quality.</li>
            <li data-i18n="projects.p11.d3">Generated and exported point clouds in PLY format, enabling seamless visualization and analysis in 3D modeling applications.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/Stereo-Point-Cloud', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project5-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
          <!-- No Live Demo -->
        </div>
      </div><!-- Project 6 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 6" class="project-img" src="./assets/unet.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p12.title">Defect Detection in Prints Using U-Net</h2>
        <p class="project-info" data-i18n="projects.p12.info">Implemented a U-Net model for defect detection, achieving 95% precision and reducing manual inspection time by 50%.</p>
        <div class="project-skills">
          <span class="skill-chip">Defect injection</span>
          <span class="skill-chip">scikit-image</span>
          <span class="skill-chip">Augmentation</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project6-details">
          <ul>
            <li data-i18n="projects.p12.d1">Implemented a U-Net-based model for defect detection, achieving 95% precision in quality assurance.</li>
            <li data-i18n="projects.p12.d2">Built an AI pipeline processing 1000+ images per day, enhancing data throughput by 25%.</li>
            <li data-i18n="projects.p12.d3">Automated defect detection reporting, delivering real-time insights to quality control teams.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/Unet', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project6-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div><!-- Project 7 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 7" class="project-img" src="./assets/predictive.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p13.title">Predictive Maintenance Using XGBoost</h2>
        <p class="project-info" data-i18n="projects.p13.info">Built a predictive maintenance model using XGBoost, achieving high accuracy in failure prediction for industrial systems.</p>
        <div class="project-skills">
          <span class="skill-chip">XGBoost</span>
          <span class="skill-chip">Python</span>
          <span class="skill-chip">Data filtering</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project7-details">
          <ul>
            <li data-i18n="projects.p13.d1">Developed an end-to-end predictive maintenance model leveraging XGBoost for industrial failure prediction.</li>
            <li data-i18n="projects.p13.d2">Achieved 98% accuracy by tuning model hyperparameters and implementing advanced analytics.</li>
            <li data-i18n="projects.p13.d3">Automated reporting and insights generation, enhancing operational efficiency.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/Predictive-Maintenance-Using-XGBoost', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project7-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div><!-- Project 8-->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 8" class="project-img" src="./assets/RL.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p14.title">Reinforcement Learning for RRR Robot</h2>
        <p class="project-info" data-i18n="projects.p14.info">Implemented a RL model for end effector path planning, optimizing robot arm trajectories in a 3D environment.</p>
        <div class="project-skills">
          <span class="skill-chip">Reinforcement Learning</span>
          <span class="skill-chip">MATLAB</span>
          <span class="skill-chip">Python</span>
          <span class="skill-chip">Kinematics</span>
        </div>

        <!-- More Details -->
        <div class="project-details hidden" id="project8-details">
          <ul>
            <li data-i18n="projects.p14.d1">Developed and implemented RL-based trajectory optimization in MATLAB, improving end-effector accuracy by 30% in reaching target positions.</li>
            <li data-i18n="projects.p14.d2">Trained the robot over 1,000 episodes using reward-based learning, reducing path deviation by 25% and ensuring efficient motion planning.</li>
            <li data-i18n="projects.p14.d3">Simulated and validated RL policies in MATLAB, achieving an 85% success rate in autonomously selecting optimal paths for task execution.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/Reinforcement-Learning-For-3DOF-Robot', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project8-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
          <!-- No Live Demo -->
        </div>
      </div><!-- Project 9 -->
      <div class="project-card">
        <div class="project-img-container">
          <img alt="Project 9" class="project-img" src="./assets/ecg.png" />
        </div>
        <h2 class="project-title" data-i18n="projects.p15.title">ECG Signal Classification with AI</h2>
        <p class="project-info" data-i18n="projects.p15.info">Developed a deep learning model for classifying ECG signals, achieving 99% accuracy in detecting cardiac anomalies.</p>
        <div class="project-skills">
          <span class="skill-chip">ECG / Biosignals</span>
          <span class="skill-chip">MATLAB</span>
          <span class="skill-chip">Signal Processing</span>
        </div>
        <!-- More Details -->
        <div class="project-details hidden" id="project9-details">
          <ul>
            <li data-i18n="projects.p15.d1">Developed a deep learning model in Python for ECG signal classification, achieving 99% accuracy in detecting abnormal heart rhythms.</li>
            <li data-i18n="projects.p15.d2">Preprocessed and segmented raw ECG data, improving model training efficiency by 40% through feature extraction and noise reduction.</li>
            <li data-i18n="projects.p15.d3">Optimized model inference speed, reducing prediction time by 30%, enabling real-time arrhythmia detection for potential clinical applications.</li>
          </ul>
        </div>
        <div class="btn-container">
          <button class="btn project-btn" data-i18n="buttons.github" onclick="window.open('https://github.com/vedantchavan004/ECG-Classification', '_blank', 'noopener,noreferrer')">
            Github
          </button>
          <button aria-controls="project9-details" class="btn project-btn more-details-btn" data-i18n="buttons.more_details">More Details</button>
        </div>
      </div>
    </div>
    <!-- View More Button -->
    <div class="view-more-container">
      <button class="btn view-more-btn" data-i18n="buttons.view_more" onclick="toggleMoreProjects()">
        View More Projects
      </button>
    </div>
    <!-- Arrow to Next Section -->
  </section>
  <!-- Languages Section -->
  <section id="languages">
    <div class="languages-header">
      <p class="section__text__p1" data-i18n="languages.subtitle">Additional Skills</p>
      <h1 class="title" data-i18n="languages.title">Language Proficiency</h1>
    </div>
    <div class="languages-grid">
      <!-- English Card -->
      <div class="language-card">
        <h2>English</h2>
        <p class="proficiency">C1</p>
      </div>
      <!-- German Card -->
      <div class="language-card">
        <h2>German</h2>
        <p class="proficiency">B1</p>
      </div>
      <!-- Hindi/Marathi Card -->
      <div class="language-card">
        <h2>Hindi , Marathi</h2>
        <p class="proficiency">Fluent</p>
      </div>
    </div>
  </section>
  <!-- Certifications Section -->
  <section id="certifications">
    <div class="certifications-header">
      <p class="section__text__p1" data-i18n="projects.subtitle">Courses</p>
      <h1 class="title">Certifications</h1>
    </div>
    <div class="certifications-grid">
      <a class="certification-link" href="https://catalog-education.oracle.com/ords/certview/sharebadge?id=457089C76BBE01A5FFC772B39ACB8578B553FBCD0130E3EE89ED453EEC082A3C" target="_blank" rel="noopener noreferrer">
        <div class="certification-card">
          <h2>OCI Generative AI Professional</h2>
          <p class="institute">Oracle</p>
        </div>
      </a>
      <a class="certification-link" href="assets/cdac.pdf" target="_blank" rel="noopener noreferrer">
        <div class="certification-card">
          <h2>Diploma in Advanced Computing</h2>
          <p class="institute">CDAC</p>
        </div>
      </a>
      <a class="certification-link" href="assets/ML.pdf" target="_blank" rel="noopener noreferrer">
        <div class="certification-card">
          <h2>Machine Learning</h2>
          <p class="institute">DeepLearning.AI - Coursera</p>
        </div>
      </a>
      <a class="certification-link" href="assets/ACVT.pdf" target="_blank" rel="noopener noreferrer">
        <div class="certification-card">
          <h2>Advanced Computer Vision with TensorFlow</h2>
          <p class="institute">DeepLearning.AI - Coursera</p>
        </div>
      </a>
      <a class="certification-link" href="assets/GDLT.pdf" target="_blank" rel="noopener noreferrer">
        <div class="certification-card">
          <h2>Generative Deep Learning with TensorFlow</h2>
          <p class="institute">DeepLearning.AI - Coursera</p>
        </div>
      </a>
    </div>
  </section>
  <!-- Contact Section -->
  <section id="contact">
    <p class="section__text__p1" data-i18n="contact.subtitle">Get in Touch</p>
    <h1 class="title" data-i18n="contact.title">Contact Me</h1>
    <div class="contact-form-container">
      <form id="contact-form">
        <div class="form-group">
          <label for="name">Name</label>
          <input data-i18n-attr="placeholder:contact.name_ph" id="name" name="user_name" required="" type="text" />
        </div>
        <div class="form-group">
          <label for="email">Email</label>
          <input data-i18n-attr="placeholder:contact.email_ph" id="email" name="user_email" required="" type="email" />
        </div>
        <div class="form-group">
          <label for="subject">Subject</label>
          <input data-i18n-attr="placeholder:contact.subject_ph" id="subject" name="subject" required="" type="text" />
        </div>
        <div class="form-group">
          <label for="message">Message</label>
          <textarea data-i18n-attr="placeholder:contact.message_ph" id="message" name="message" required="" rows="5"></textarea>
        </div>
        <button class="btn submit-btn" data-i18n="contact.send" type="submit">Send Message</button>
      </form>
      <div class="feedback" id="contact-feedback">Message has been sent!</div>
    </div>
  </section>
  <!-- EmailJS SDK -->
  <script src="https://cdn.emailjs.com/dist/email.min.js" type="text/javascript"></script>
  <script type="text/javascript">
    (function() {
      emailjs.init("nMTEsAWrT1ZizUdyq");
    })();
  </script>
  <!-- Footer -->
  <footer>
    <nav>
      <ul class="nav-links">
        <li><a data-i18n="nav.about" href="#about">About</a></li>
        <li><a data-i18n="nav.skills" href="#skills">Skills</a></li>
        <li><a data-i18n="nav.experience" href="#experience">Experience</a></li>
        <li><a data-i18n="nav.projects" href="#projects">Projects</a></li>
        <li><a data-i18n="nav.contact" href="#contact">Contact</a></li>
      </ul>
    </nav>
    <p>Copyright © 2025 Vedant Chavan. All Rights Reserved.</p>
  </footer>
  <script src="script.js"></script>

</body>

</html>
